| Name | Type | Default | Description |
|------|------|---------|-------------|
| `id` | `str` | `"gpt-4o"` | The id of the OpenAI model to use. |
| `name` | `str` | `"OpenAIChat"` | The name of this chat model instance. |
| `provider` | `str` | `"OpenAI " + id` | The provider of the model. |
| `store` | `Optional[bool]` | `None` | Whether or not to store the output of this chat completion request for use in the model distillation or evals products. |
| `frequency_penalty` | `Optional[float]` | `None` | Penalizes new tokens based on their frequency in the text so far. |
| `logit_bias` | `Optional[Any]` | `None` | Modifies the likelihood of specified tokens appearing in the completion. |
| `logprobs` | `Optional[bool]` | `None` | Include the log probabilities on the logprobs most likely tokens. |
| `max_tokens` | `Optional[int]` | `None` | The maximum number of tokens to generate in the chat completion. |
| `presence_penalty` | `Optional[float]` | `None` | Penalizes new tokens based on whether they appear in the text so far. |
| `response_format` | `Optional[Any]` | `None` | An object specifying the format that the model must output. |
| `seed` | `Optional[int]` | `None` | A seed for deterministic sampling. |
| `stop` | `Optional[Union[str, List[str]]]` | `None` | Up to 4 sequences where the API will stop generating further tokens. |
| `temperature` | `Optional[float]` | `None` | Controls randomness in the model's output. |
| `top_logprobs` | `Optional[int]` | `None` | How many log probability results to return per token. |
| `user` | `Optional[str]` | `None` | A unique identifier representing your end-user. |
| `top_p` | `Optional[float]` | `None` | Controls diversity via nucleus sampling. |
| `extra_headers` | `Optional[Any]` | `None` | Additional headers to send with the request. |
| `extra_query` | `Optional[Any]` | `None` | Additional query parameters to send with the request. |
| `request_params` | `Optional[Dict[str, Any]]` | `None` | Additional parameters to include in the request. |
| `api_key` | `Optional[str]` | `None` | The API key for authenticating with OpenAI. |
| `organization` | `Optional[str]` | `None` | The organization to use for API requests. |
| `base_url` | `Optional[Union[str, httpx.URL]]` | `None` | The base URL for API requests. |
| `timeout` | `Optional[float]` | `None` | The timeout for API requests. |
| `max_retries` | `Optional[int]` | `None` | The maximum number of retries for failed requests. |
| `default_headers` | `Optional[Any]` | `None` | Default headers to include in all requests. |
| `default_query` | `Optional[Any]` | `None` | Default query parameters to include in all requests. |
| `http_client` | `Optional[httpx.Client]` | `None` | An optional pre-configured HTTP client. |
| `client_params` | `Optional[Dict[str, Any]]` | `None` | Additional parameters for client configuration. |
| `client` | `Optional[OpenAIClient]` | `None` | The OpenAI client instance. |
| `async_client` | `Optional[AsyncOpenAIClient]` | `None` | The asynchronous OpenAI client instance. |
| `structured_outputs` | `bool` | `False` | Whether to use the structured outputs from the Model. |
| `supports_structured_outputs` | `bool` | `True` | Whether the Model supports structured outputs. |
| `add_images_to_message_content` | `bool` | `True` | Whether to add images to the message content. |