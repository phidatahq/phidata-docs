---
title: Ollama Embedder
sidebarTitle: Ollama
---

The `OllamaEmbedder` can be used to embed text data into vectors locally using Ollama. Note: The model used for generating embeddings needs to runn locally.

## Usage

```python
from phi.assistant import Assistant, AssistantKnowledge
from phi.vectordb.pgvector import PgVector2
from phi.embedder.ollama import OllamaEmbedder

# Create knowledge base
knowledge_base=AssistantKnowledge(
    vector_db=PgVector2(
        db_url=db_url,
        collection=embeddings_table,
        embedder=OllamaEmbedder(),
    ),
    # 2 references are added to the prompt
    num_documents=2,
),

# Add information to the knowledge base
knowledge_base.load_text("The sky is blue")

# Add the knowledge base to the Assistant
assistant = Assistant(knowledge_base=knowledge_base)
```

## Params

<ResponseField name="model" type="str" default="openhermes">
  The name of the model used for generating embeddings.
</ResponseField>
<ResponseField name="dimensions" type="int" default="4096">
  The dimensionality of the embeddings generated by the model.
</ResponseField>
<ResponseField name="host" type="str">
  The host address for the API endpoint.
</ResponseField>
<ResponseField name="timeout" type="Any">
  The timeout duration for API requests.
</ResponseField>
<ResponseField name="options" type="Any">
  Additional options for configuring the API request.
</ResponseField>
<ResponseField name="client_kwargs" type="Optional[Dict[str, Any]]">
  Additional keyword arguments for configuring the API client. Optional.
</ResponseField>
<ResponseField name="ollama_client" type="Optional[OllamaClient]">
  An instance of the OllamaClient to use for making API requests. Optional.
</ResponseField>
